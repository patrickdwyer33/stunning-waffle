{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "jax.default_device = jax.devices(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = jnp.array([[1, 1, 0], [1, 1, 1], [0, 1, 1]], dtype=jnp.float64)\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 33\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(key, layer_sizes):\n",
    "    scale_weights = 1e-1\n",
    "    scale_biases = 1e-1\n",
    "    params = []\n",
    "    for n_in, n_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        params.append(dict(weights=scale_weights * jax.random.normal(subkey, (n_in, n_out)), \n",
    "                           biases=scale_biases * jax.random.normal(subkey, (n_out,)))\n",
    "                      )\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [9, 128, 128, 9]\n",
    "params = init_params(key, layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'biases': (128,), 'weights': (9, 128)},\n",
       " {'biases': (128,), 'weights': (128, 128)},\n",
       " {'biases': (9,), 'weights': (128, 9)}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.34678932, 0.33656011, 0.31665057],\n",
       "       [0.22175218, 0.32623454, 0.45201328],\n",
       "       [0.3609601 , 0.28891771, 0.35012219]], dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jax.jit\n",
    "def forward(params, x):\n",
    "    x = jnp.ravel(x)\n",
    "    *hidden, last = params\n",
    "    for layer in hidden:\n",
    "        x = jax.nn.relu(x @ layer['weights'] + layer['biases'])\n",
    "    raw_out = jnp.reshape(x @ last['weights'] + last['biases'], (3, 3))\n",
    "    out = jax.nn.softmax(raw_out, axis=1)\n",
    "    return out\n",
    "forward(params, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def group_loss(size, bad_edge_sum):\n",
    "    max_size = size * (size - 1)\n",
    "    max_size = jnp.where(max_size < 1., 1., max_size)\n",
    "    return bad_edge_sum / max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4., dtype=float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, x, y):\n",
    "    pred = forward(params, x)\n",
    "    group_ids = jnp.argmax(pred, axis=1)\n",
    "    groups = {}\n",
    "    for x_idx, group_id in enumerate(group_ids):\n",
    "        if not groups.get(group_id, False):\n",
    "            groups[group_id] = {\"size\": 0, \"x_idxes\": set(), \"bad_edge_sum\": 0}\n",
    "        groups[group_id][\"size\"] += 1\n",
    "        groups[group_id][\"x_idxes\"].add(x_idx)\n",
    "    for _, group in groups.items():\n",
    "        for x_idx in group[\"x_idxes\"]:\n",
    "            for other_idx in range(x.shape[0]):\n",
    "                if other_idx == x_idx: continue\n",
    "                if other_idx not in group[\"x_idxes\"]: group[\"bad_edge_sum\"] += jnp.where(x[x_idx, other_idx] == 1, 1, 0)\n",
    "                if other_idx in group[\"x_idxes\"]: group[\"bad_edge_sum\"] += jnp.where(x[x_idx, other_idx] == 0, 1, 0)\n",
    "    group_infos = {group_id: {\"size\": group[\"size\"], \"bad_edge_sum\": group[\"bad_edge_sum\"]} for group_id, group in groups.items()}\n",
    "    losses = list(map(lambda group: group_loss(group[\"size\"], group[\"bad_edge_sum\"]), list(group_infos.values())))\n",
    "    loss = jnp.sum(jnp.asarray(losses))\n",
    "    return loss\n",
    "loss_fn(params, X, forward(params, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
